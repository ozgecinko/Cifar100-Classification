# -*- coding: utf-8 -*-
"""Cifar100Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Zs1QUwriCKKeDh7pgKxQBoMedKLt7mR
"""

import os
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
import tensorflow as tf
import keras

from tensorflow.keras.datasets import cifar100 #Kullanacağımız veriseti
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping # Model overfitting problemiyle karşılaştığı için

from tensorflow.keras.preprocessing.image import ImageDataGenerator # Data augmentation için
from tensorflow.keras.preprocessing import image

from tensorflow.keras.utils import to_categorical

from keras.utils.vis_utils import plot_model #Modeli çizmek için
from sklearn.metrics import confusion_matrix, classification_report # Confusion matrisi için

# CIFAR-100 verisetini eğitim ve test olarak ayırmak üzere indirdim.
(train_image, train_label), (test_image, test_label) = cifar100.load_data()

# Verisetinde toplam 50000 eğitim verisi, 10000 test verisi bulunur.
print(train_image.shape, train_label.shape)
print(test_image.shape, test_label.shape)

# Benim okul numarama göre belirlenen sınıflar şunlardır:
# 19=cattle 22=clock 37=house 49=mountain 61=plate 86=telephone 90=train
my_classes = dict({19:"cattle",22:"clock",37:"house",49:"mountain",61:"plate",86:"telephone",90:"train"})

# Verisetinden belirlenen sınıfları çıkarıp dosyalara kaydeden fonksiyon.
def save_images(x,y,classes,file_path):
    for i,j in classes.items():
        class_path = os.path.join(file_path, j)
        os.mkdir(class_path)
        photos = x[y[:,0] == i]
        for k,photo in enumerate(photos):
            plt.imsave(class_path +"/"+ str(k)+".png",photo)

# Verisetinde kullandığım sınıfları cifar100_classes isimli dosyaya kaydettim.
dataset_path = "cifar100_classes"

os.mkdir(dataset_path)
train_dir = os.path.join(dataset_path, 'train')
os.mkdir(train_dir)
test_dir = os.path.join(dataset_path, 'test')
os.mkdir(test_dir)

save_images(train_image,train_label,my_classes,train_dir)
save_images(test_image,test_label,my_classes,test_dir)

print("Working Directory Contents:", os.listdir(train_dir))

# Belirlenen sınıfların örnek görüntüsünü alan fonksiyon.
def show_class_photos():
  fig,ax = plt.subplots(7,10,figsize=(16,9))

  labels = list(my_classes.keys())

  for i in range(7):
      photos = train_image[train_label[:,0] == labels[i]]
      ax[i,0].axis("off")
      ax[i,0].text(0,0.5,my_classes[labels[i]], fontsize=15, fontweight = 'bold')
      for j in range(1,10):
          ax[i,j].axis("off")
          ax[i,j].imshow(photos[j])
          
  plt.show()

# Sınıflardan örnekler gösterdim.
show_class_photos()

# Daha fazla veri örneğine sahip olmak için Data Augmentation gerçekleştirdim.
train_datagen = image.ImageDataGenerator(rescale=1./255,
                                         featurewise_center=False,             # Giriş verilerinin ortalamasının sıfırlanması.
                                         samplewise_center=False,              # Her örnek verinin ortalamasının 0'a eşitlenmesi.
                                         featurewise_std_normalization=False,  # Giriş verilerinin, verisetinin standart varyans değerine bölünmesi.
                                         samplewise_std_normalization=False,   # Her verinin standart varyans değerine bölünmesi.
                                         zca_whitening=False,                  # "ZCA whitening" metodunun uygulanması.
                                         rotation_range=0,                     # Görüntülerin bir sınır aralığında rastgele döndürür.
                                         width_shift_range=0.1,                # Görüntüler rastgele yatay olarak kaydırılır.
                                         height_shift_range=0.1,               # Görüntüler rastgele dikey olarak kaydırılır.
                                         shear_range=0.15,                     # Görüntüleri rastgele kırpar.
                                         zoom_range=0.15,                      # Görüntüleri rastgele yakınlaştırır.
                                         horizontal_flip=True,                 # Fotoğrafı yatay düzlemde rastgele çevirir.
                                         vertical_flip=False)                  # Resimlerin dikey olarak çevirir.
        

test_datagen = image.ImageDataGenerator(rescale=1./255)

train_data_gen = train_datagen.flow_from_directory(directory = train_dir, 
                                                   target_size = (32,32), 
                                                   class_mode = "categorical", 
                                                   batch_size = 50, # Her batch 50 eğitim görüntüsü içerir.
                                                   shuffle=True,
                                                   seed=42) 
                                                   
test_data_gen = test_datagen.flow_from_directory(directory = test_dir, 
                                                 target_size = (32,32),
                                                 class_mode = "categorical",
                                                 batch_size = 50,
                                                 shuffle=False, 
                                                 seed=42)

# Kendi sınıflarımı kullanmak üzere ImageDataGenerator yineleyiciden eğitim ve test verilerini aldım.
train_data, train_labels = train_data_gen.next()
test_data, test_labels = test_data_gen.next()

# Okul numaramda belirlenen sınıflar 7 taneydi.
# 7 sınıfta toplamda 3500 eğitim verisi, 700 test verisi bulunur.
print(train_data_gen.samples)
print(test_data_gen.samples)

# Modeli oluşturdum.
model=Sequential()
model.add(Conv2D(64, (3,3),
                 activation='relu', 
                 padding='same',
                 strides = (1,1),
                 input_shape=(32,32,3)))
model.add(MaxPool2D((2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(128, (3,3),
                 padding='same',
                 activation='relu'))
model.add(MaxPool2D((2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(256, (3,3),
                 padding='same',
                 activation='relu'
                 ))
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.50))
model.add(Dense(len(my_classes),activation="softmax"))
model.summary()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_data_gen,
                    steps_per_epoch=train_data_gen.samples//50,
                    epochs=34,
                    validation_data=test_data_gen,
                    validation_steps=test_data_gen.samples//50)

#Eğitim sırasındaki metriklerin (accuracy, loss) eğilimlerini çizme
fig, ax = plt.subplots(1, 2, figsize = (30, 5))
ax = ax.ravel()

for i, metric in enumerate(["accuracy", "loss"]):
    ax[i].plot(history.history[metric])
    ax[i].plot(history.history["val_" + metric])
    ax[i].set_title("Model {}".format(metric))
    ax[i].set_xlabel("Epochs")
    ax[i].set_ylabel(metric)
    ax[i].legend(["train", "val"])


test_scores = model.evaluate(test_data_gen, steps=test_data_gen.samples//50)
print("Testing Accuracy: %.2f%%"%(test_scores[1] * 100))

# Her batch 50 eğitim görüntüsü içerdiği için bir batchteki tahmin edilen sınıflara bakmak istedim.
val_image_batch, val_label_batch = next(iter(test_data_gen))
true_label_ids = np.argmax(val_label_batch, axis=-1)
print("Validation batch shape:", val_image_batch.shape)

dataset_labels = sorted(train_data_gen.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print(dataset_labels)

tf_model_predictions = model.predict(val_image_batch)
print("Prediction results shape:", tf_model_predictions.shape)

# Her batch 50 eğitim görüntüsü içerdiği için bir batchteki tahmin edilen sınıflara yani toplamda 50 sınıfa baktım.
predicted_ids = np.argmax(tf_model_predictions, axis=-1)
predicted_labels = dataset_labels[predicted_ids]
print(predicted_labels)
print(len(predicted_labels))

# Bir batchteki tahmin edilen resimlerin doğruluğunu gösterdim.
# Resim doğru tahmin edilmişse sınıf ismi yeşil renklidir.
# Resim yanlış tahmin edilmişse sınıf ismi kırmızı renklidir.
plt.figure(figsize=(10,10))
plt.subplots_adjust(hspace=0.5)
for n in range(0, 48):
  plt.subplot(7,7,n+1)
  plt.imshow(val_image_batch[n])
  color = "green" if predicted_ids[n] == true_label_ids[n] else "red"
  plt.title(predicted_labels[n].title(), color=color)
  plt.axis('off')

# Karmaşıklık matrisi (confution matrix) ve sınıflandırma raporu oluşturdum.
Labels = ['cattle', 'house', 'train', 'telephone', 'plate', 'clock', 'mountain']

Predictions = model.predict(test_data_gen, test_data_gen.samples // 50)
predictions = np.argmax(Predictions, axis=1)

print(confusion_matrix(test_data_gen.classes, predictions))
cm = confusion_matrix(test_data_gen.classes, predictions)

print(classification_report(test_data_gen.classes, predictions, target_names=Labels))

# Karmaşıklık matrisi (confution matrix) bir grafikte gösterdim.
plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')

ax = sns.heatmap(cm, cmap='Greens', annot=True, fmt='d', xticklabels=Labels, yticklabels=Labels)

plt.title('Confusion Matrix')
plt.xlabel('Prediction')
plt.ylabel('Truth')
plt.show(ax)

# Görüntüleri gösteren fonksiyon.
def show_image(img_path):
  img = mpimg.imread(img_path)
  imgplot = plt.imshow(img)
  return plt.show()

def predict_label(img_path):
	test_image = image.load_img(img_path, target_size=(32,32))
	test_image = image.img_to_array(test_image)/255.0
	test_image = test_image.reshape(1, 32,32,3)
	
	predict_x=model.predict(test_image) 
	classes_x=np.argmax(predict_x,axis=1)
 
	return Labels[classes_x[0]], show_image(img_path)

# Her sınıftan bir görüntüyü test ettim.
predict_label('/content/cifar100_classes/test/cattle/6.png')
predict_label('/content/cifar100_classes/test/clock/10.png')
predict_label('/content/cifar100_classes/test/house/7.png')
predict_label('/content/cifar100_classes/test/mountain/21.png')
predict_label('/content/cifar100_classes/test/plate/25.png')
predict_label('/content/cifar100_classes/test/telephone/35.png')
predict_label('/content/cifar100_classes/test/train/44.png')

# Bütün sınıfların tahmin edilen değerlerle karşılaştırılmasını bir "results.csv" dosyasına kaydettim.
# Bu dosyada hangi verilerin doğru hangi verilerin yanlış olduğunu net bir şekilde görürüz.
batch_size = 50
STEP_SIZE_TEST=test_data_gen.n//test_data_gen.batch_size
test_data_gen.reset()
pred=model.predict(test_data_gen, steps=STEP_SIZE_TEST, verbose=1)

predicted_class_indices=np.argmax(pred,axis=1)

labels = (train_data_gen.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]

filenames=test_data_gen.filenames
results=pd.DataFrame({"Filename":filenames,
                      "Predictions":predictions})
results.to_csv("results.csv",index=False)

# Modelin kaydedileceği yer belirlenir.
model.save(os.path.join("./savedmodels/","cifar100_model.h5"))

pretrained_model = keras.models.load_model("/content/savedmodels/cifar100_model.h5")

plot_model(pretrained_model, to_file="model_plot.png", show_shapes=True, show_layer_names=True)

#Test resimlerinden bir görüntünün sınıfına baktım.
result = model.predict(test_image[1:2])
print(test_label[1])